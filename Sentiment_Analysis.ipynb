{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "957c084c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\nicol\\anaconda\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: keras~=2.6 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow) (1.39.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: tensorflow_datasets in c:\\users\\nicol\\anaconda\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow_datasets) (3.17.3)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow_datasets) (1.2.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow_datasets) (0.12.0)\n",
      "Requirement already satisfied: promise in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: dill in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow_datasets) (0.3.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow_datasets) (2.25.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow_datasets) (4.59.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow_datasets) (5.2.2)\n",
      "Requirement already satisfied: future in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow_datasets) (0.18.2)\n",
      "Requirement already satisfied: termcolor in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow_datasets) (1.19.5)\n",
      "Requirement already satisfied: six in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow_datasets) (1.15.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow_datasets) (20.3.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from importlib-resources->tensorflow_datasets) (3.4.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from tensorflow-metadata->tensorflow_datasets) (1.53.0)\n"
     ]
    }
   ],
   "source": [
    "# Installation des librairies tensorflow\n",
    "!pip install tensorflow\n",
    "# Et tensorflow_datasets pour récupérer la BDD\n",
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "878edc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0-dev20210902'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importation des librairies\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pathlib \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11db7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation de la BDD\n",
    "data = pd.read_csv(\"https://go.aws/314bBDq\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f69c74af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>review</th>\n",
       "      <th>stars</th>\n",
       "      <th>date_format</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>review_format</th>\n",
       "      <th>review_lang</th>\n",
       "      <th>month_year</th>\n",
       "      <th>review_len</th>\n",
       "      <th>review_nb_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efb62a167fee5cf3678b24427de8e31f</td>\n",
       "      <td>Génial, fabuleux, exceptionnel ! J'aimerais qu...</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-09-29 18:17:00</td>\n",
       "      <td>18:17</td>\n",
       "      <td>18</td>\n",
       "      <td>Ven</td>\n",
       "      <td>génial  fabuleux  exceptionnel   j aimerais qu...</td>\n",
       "      <td>french</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>115</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e3be4f9c9e0b9572bfb2a5f88497bb14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-09-29 17:29:00</td>\n",
       "      <td>17:29</td>\n",
       "      <td>17</td>\n",
       "      <td>Ven</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1b8e5760162d867e9b9ca80f645bdc60</td>\n",
       "      <td>Toujours aussi magic, féerique !</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-09-29 16:46:00</td>\n",
       "      <td>16:46</td>\n",
       "      <td>16</td>\n",
       "      <td>Ven</td>\n",
       "      <td>toujours aussi magic  féerique</td>\n",
       "      <td>french</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fa330e5891a1bb486c3e9bf95c098726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-09-29 15:52:00</td>\n",
       "      <td>15:52</td>\n",
       "      <td>15</td>\n",
       "      <td>Ven</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1a693206aee1a2412d4bd9e45b80ec5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-09-29 15:29:00</td>\n",
       "      <td>15:29</td>\n",
       "      <td>15</td>\n",
       "      <td>Ven</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id  \\\n",
       "0  efb62a167fee5cf3678b24427de8e31f   \n",
       "1  e3be4f9c9e0b9572bfb2a5f88497bb14   \n",
       "2  1b8e5760162d867e9b9ca80f645bdc60   \n",
       "3  fa330e5891a1bb486c3e9bf95c098726   \n",
       "4  c1a693206aee1a2412d4bd9e45b80ec5   \n",
       "\n",
       "                                              review  stars  \\\n",
       "0  Génial, fabuleux, exceptionnel ! J'aimerais qu...      5   \n",
       "1                                                NaN      2   \n",
       "2                   Toujours aussi magic, féerique !      5   \n",
       "3                                                NaN      5   \n",
       "4                                                NaN      3   \n",
       "\n",
       "           date_format time_of_day  hour_of_day day_of_week  \\\n",
       "0  2017-09-29 18:17:00       18:17           18         Ven   \n",
       "1  2017-09-29 17:29:00       17:29           17         Ven   \n",
       "2  2017-09-29 16:46:00       16:46           16         Ven   \n",
       "3  2017-09-29 15:52:00       15:52           15         Ven   \n",
       "4  2017-09-29 15:29:00       15:29           15         Ven   \n",
       "\n",
       "                                       review_format review_lang month_year  \\\n",
       "0  génial  fabuleux  exceptionnel   j aimerais qu...      french    2017-09   \n",
       "1                                                NaN         NaN    2017-09   \n",
       "2                   toujours aussi magic  féerique        french    2017-09   \n",
       "3                                                NaN         NaN    2017-09   \n",
       "4                                                NaN         NaN    2017-09   \n",
       "\n",
       "   review_len  review_nb_words  \n",
       "0         115               19  \n",
       "1           0                0  \n",
       "2          32                4  \n",
       "3           0                0  \n",
       "4           0                0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview de la BDD\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4079a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne garde que les avis en français\n",
    "dataset= data.loc[data[\"review_lang\"]==\"french\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d71c540c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>review</th>\n",
       "      <th>stars</th>\n",
       "      <th>date_format</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>review_format</th>\n",
       "      <th>review_lang</th>\n",
       "      <th>month_year</th>\n",
       "      <th>review_len</th>\n",
       "      <th>review_nb_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efb62a167fee5cf3678b24427de8e31f</td>\n",
       "      <td>Génial, fabuleux, exceptionnel ! J'aimerais qu...</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-09-29 18:17:00</td>\n",
       "      <td>18:17</td>\n",
       "      <td>18</td>\n",
       "      <td>Ven</td>\n",
       "      <td>génial  fabuleux  exceptionnel   j aimerais qu...</td>\n",
       "      <td>french</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>115</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1b8e5760162d867e9b9ca80f645bdc60</td>\n",
       "      <td>Toujours aussi magic, féerique !</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-09-29 16:46:00</td>\n",
       "      <td>16:46</td>\n",
       "      <td>16</td>\n",
       "      <td>Ven</td>\n",
       "      <td>toujours aussi magic  féerique</td>\n",
       "      <td>french</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>726b1a3e2664e8b075129bcd643dbf56</td>\n",
       "      <td>En vacances en région parisienne nous nous som...</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-09-29 00:37:00</td>\n",
       "      <td>00:37</td>\n",
       "      <td>0</td>\n",
       "      <td>Ven</td>\n",
       "      <td>en vacances en région parisienne nous nous som...</td>\n",
       "      <td>french</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>172</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8a71763fbb3da7436b957681b24cc404</td>\n",
       "      <td>Tropbeaufinalpleinlesyeuxoreil</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-09-29 00:16:00</td>\n",
       "      <td>00:16</td>\n",
       "      <td>0</td>\n",
       "      <td>Ven</td>\n",
       "      <td>tropbeaufinalpleinlesyeuxoreil</td>\n",
       "      <td>french</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ce7abd7798ee036d667c0ad84b85daa7</td>\n",
       "      <td>L'univers Disney reste merveilleux. Toutefois ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-09-28 20:24:00</td>\n",
       "      <td>20:24</td>\n",
       "      <td>20</td>\n",
       "      <td>Jeu</td>\n",
       "      <td>l univers disney reste merveilleux  toutefois ...</td>\n",
       "      <td>french</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>148</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id  \\\n",
       "0   efb62a167fee5cf3678b24427de8e31f   \n",
       "2   1b8e5760162d867e9b9ca80f645bdc60   \n",
       "11  726b1a3e2664e8b075129bcd643dbf56   \n",
       "12  8a71763fbb3da7436b957681b24cc404   \n",
       "23  ce7abd7798ee036d667c0ad84b85daa7   \n",
       "\n",
       "                                               review  stars  \\\n",
       "0   Génial, fabuleux, exceptionnel ! J'aimerais qu...      5   \n",
       "2                    Toujours aussi magic, féerique !      5   \n",
       "11  En vacances en région parisienne nous nous som...      2   \n",
       "12                     Tropbeaufinalpleinlesyeuxoreil      5   \n",
       "23  L'univers Disney reste merveilleux. Toutefois ...      4   \n",
       "\n",
       "            date_format time_of_day  hour_of_day day_of_week  \\\n",
       "0   2017-09-29 18:17:00       18:17           18         Ven   \n",
       "2   2017-09-29 16:46:00       16:46           16         Ven   \n",
       "11  2017-09-29 00:37:00       00:37            0         Ven   \n",
       "12  2017-09-29 00:16:00       00:16            0         Ven   \n",
       "23  2017-09-28 20:24:00       20:24           20         Jeu   \n",
       "\n",
       "                                        review_format review_lang month_year  \\\n",
       "0   génial  fabuleux  exceptionnel   j aimerais qu...      french    2017-09   \n",
       "2                    toujours aussi magic  féerique        french    2017-09   \n",
       "11  en vacances en région parisienne nous nous som...      french    2017-09   \n",
       "12                     tropbeaufinalpleinlesyeuxoreil      french    2017-09   \n",
       "23  l univers disney reste merveilleux  toutefois ...      french    2017-09   \n",
       "\n",
       "    review_len  review_nb_words  \n",
       "0          115               19  \n",
       "2           32                4  \n",
       "11         172               25  \n",
       "12          30                1  \n",
       "23         148               23  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview de la BDD en français\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90ee1d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne garde que les colonnes des avis et du nombre d'étoile par observation\n",
    "columns = [\"review_format\",\"stars\"]\n",
    "datafinal= dataset[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b6c0381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_format</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>génial  fabuleux  exceptionnel   j aimerais qu...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toujours aussi magic  féerique</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>en vacances en région parisienne nous nous som...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tropbeaufinalpleinlesyeuxoreil</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>l univers disney reste merveilleux  toutefois ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        review_format  stars\n",
       "0   génial  fabuleux  exceptionnel   j aimerais qu...      5\n",
       "2                    toujours aussi magic  féerique        5\n",
       "11  en vacances en région parisienne nous nous som...      2\n",
       "12                     tropbeaufinalpleinlesyeuxoreil      5\n",
       "23  l univers disney reste merveilleux  toutefois ...      4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview de la BDD cleané\n",
    "datafinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "096d4b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_format</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>génial  fabuleux  exceptionnel   j aimerais qu...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toujours aussi magic  féerique</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>en vacances en région parisienne nous nous som...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tropbeaufinalpleinlesyeuxoreil</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>l univers disney reste merveilleux  toutefois ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295057</th>\n",
       "      <td>toujours aussi magique même si à la fin du séj...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295549</th>\n",
       "      <td>séjour au top    mes enfants les plus heureux ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298475</th>\n",
       "      <td>magnifique un monde parfait  lt</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298832</th>\n",
       "      <td>oui j ai aimé car j adore disney et tout ce qu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299402</th>\n",
       "      <td>je vais à disney minimum  fois par saison car ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8474 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_format  stars\n",
       "0       génial  fabuleux  exceptionnel   j aimerais qu...      5\n",
       "2                        toujours aussi magic  féerique        5\n",
       "11      en vacances en région parisienne nous nous som...      2\n",
       "12                         tropbeaufinalpleinlesyeuxoreil      5\n",
       "23      l univers disney reste merveilleux  toutefois ...      4\n",
       "...                                                   ...    ...\n",
       "295057  toujours aussi magique même si à la fin du séj...      5\n",
       "295549  séjour au top    mes enfants les plus heureux ...      5\n",
       "298475                   magnifique un monde parfait  lt       5\n",
       "298832  oui j ai aimé car j adore disney et tout ce qu...      4\n",
       "299402  je vais à disney minimum  fois par saison car ...      5\n",
       "\n",
       "[8474 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On supprime les données non renseignées\n",
    "datafinal.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65d8cae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 2 4 3 1]\n"
     ]
    }
   ],
   "source": [
    "# Regardons le nombre de catégories pour le nombre d'étoiles\n",
    "print(datafinal[\"stars\"].unique())\n",
    "# On en a 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d32d08a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8474, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensions de la BDD\n",
    "datafinal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f056b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\nicol\\anaconda\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (4.59.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (52.0.0.post20210125)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (8.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 16:40:22.260236: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-09-27 16:40:22.260402: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.1.0/fr_core_news_sm-3.1.0-py3-none-any.whl (17.1 MB)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from fr-core-news-sm==3.1.0) (3.1.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (2.11.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (20.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (1.19.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (0.3.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (4.59.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\nicol\\anaconda\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->fr-core-news-sm==3.1.0) (1.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "# On installe spacy\n",
    "!pip install spacy\n",
    "# Pour télécharger la pipeline de tokenization\n",
    "!python -m spacy download fr_core_news_sm\n",
    "import fr_core_news_sm\n",
    "# On enregistre la pipeline dans la variable NLP \n",
    "nlp = fr_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2adc502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe la séquence de mot que l'on  va enlever dans notre corpus de ligne\n",
    "# STOP_WORDS\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c90720ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-c5a16d1f8834>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datafinal[\"review_format_clean\"] = datafinal[\"review_format\"].apply(lambda x:''.join(ch for ch in x if ch.isalnum() or ch==\" \"))\n",
      "<ipython-input-14-c5a16d1f8834>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datafinal[\"review_format_clean\"] = datafinal[\"review_format\"].apply(lambda x: x.replace(\" +\",\" \").lower().strip())\n",
      "<ipython-input-14-c5a16d1f8834>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datafinal[\"review_format_clean\"] = datafinal[\"review_format\"].apply(lambda x:\" \".join([token.lemma_ for token in nlp(x) if token.lemma_ not in STOP_WORDS]))\n"
     ]
    }
   ],
   "source": [
    "# On lemmatize le texte\n",
    "# Tout d'abord on rassemble les lignes de chaque observations pour en faire un paragraphe\n",
    "datafinal[\"review_format_clean\"] = datafinal[\"review_format\"].apply(lambda x:''.join(ch for ch in x if ch.isalnum() or ch==\" \"))\n",
    "# Puis on remplace le caractère + entre chaque ligne par un espace et on supprime tous les espaces en trop\n",
    "datafinal[\"review_format_clean\"] = datafinal[\"review_format\"].apply(lambda x: x.replace(\" +\",\" \").lower().strip())\n",
    "# On lemmatize les mots (on les traduit par leur racine commune) avec fr_core_news_sm en enlevant ceux compris dans liste de STOP_WORDS\n",
    "datafinal[\"review_format_clean\"] = datafinal[\"review_format\"].apply(lambda x:\" \".join([token.lemma_ for token in nlp(x) if token.lemma_ not in STOP_WORDS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "756ebb0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_format</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_format_clean</th>\n",
       "      <th>tokenize_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>génial  fabuleux  exceptionnel   j aimerais qu...</td>\n",
       "      <td>5</td>\n",
       "      <td>génial   fabuleux   exceptionnel    j aimerai ...</td>\n",
       "      <td>[91, 546, 465, 7, 1754, 407, 8, 5113, 1755]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toujours aussi magic  féerique</td>\n",
       "      <td>5</td>\n",
       "      <td>magic   féerique</td>\n",
       "      <td>[311, 65]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>en vacances en région parisienne nous nous som...</td>\n",
       "      <td>2</td>\n",
       "      <td>vacance région parisien décider visiter parc r...</td>\n",
       "      <td>[379, 3044, 1756, 780, 528, 5, 2088, 3725, 118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tropbeaufinalpleinlesyeuxoreil</td>\n",
       "      <td>5</td>\n",
       "      <td>tropbeaufinalpleinlesyeuxoreil</td>\n",
       "      <td>[5114]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>l univers disney reste merveilleux  toutefois ...</td>\n",
       "      <td>4</td>\n",
       "      <td>l univers disney merveilleux   toutefois regre...</td>\n",
       "      <td>[4, 366, 8, 83, 1243, 644, 35, 55, 1895, 101, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295057</th>\n",
       "      <td>toujours aussi magique même si à la fin du séj...</td>\n",
       "      <td>5</td>\n",
       "      <td>magique fin séjour rotule lol</td>\n",
       "      <td>[10, 175, 31, 10169, 401]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295549</th>\n",
       "      <td>séjour au top    mes enfants les plus heureux ...</td>\n",
       "      <td>5</td>\n",
       "      <td>séjour top     enfant heureux vouloir voir per...</td>\n",
       "      <td>[31, 44, 16, 296, 94, 24, 47, 141, 31, 45, 565...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298475</th>\n",
       "      <td>magnifique un monde parfait  lt</td>\n",
       "      <td>5</td>\n",
       "      <td>magnifique monde parfaire   lt</td>\n",
       "      <td>[25, 29, 113, 151]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298832</th>\n",
       "      <td>oui j ai aimé car j adore disney et tout ce qu...</td>\n",
       "      <td>4</td>\n",
       "      <td>oui j aimer j adore disney touche univers     ...</td>\n",
       "      <td>[178, 7, 186, 7, 76, 8, 2212, 366, 42, 16, 403...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299402</th>\n",
       "      <td>je vais à disney minimum  fois par saison car ...</td>\n",
       "      <td>5</td>\n",
       "      <td>aller disney minimum   fois saison magique pri...</td>\n",
       "      <td>[17, 8, 386, 18, 282, 10, 1180, 4, 1179, 7, 23...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8474 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_format  stars  \\\n",
       "0       génial  fabuleux  exceptionnel   j aimerais qu...      5   \n",
       "2                        toujours aussi magic  féerique        5   \n",
       "11      en vacances en région parisienne nous nous som...      2   \n",
       "12                         tropbeaufinalpleinlesyeuxoreil      5   \n",
       "23      l univers disney reste merveilleux  toutefois ...      4   \n",
       "...                                                   ...    ...   \n",
       "295057  toujours aussi magique même si à la fin du séj...      5   \n",
       "295549  séjour au top    mes enfants les plus heureux ...      5   \n",
       "298475                   magnifique un monde parfait  lt       5   \n",
       "298832  oui j ai aimé car j adore disney et tout ce qu...      4   \n",
       "299402  je vais à disney minimum  fois par saison car ...      5   \n",
       "\n",
       "                                      review_format_clean  \\\n",
       "0       génial   fabuleux   exceptionnel    j aimerai ...   \n",
       "2                                      magic   féerique     \n",
       "11      vacance région parisien décider visiter parc r...   \n",
       "12                         tropbeaufinalpleinlesyeuxoreil   \n",
       "23      l univers disney merveilleux   toutefois regre...   \n",
       "...                                                   ...   \n",
       "295057                      magique fin séjour rotule lol   \n",
       "295549  séjour top     enfant heureux vouloir voir per...   \n",
       "298475                     magnifique monde parfaire   lt   \n",
       "298832  oui j aimer j adore disney touche univers     ...   \n",
       "299402  aller disney minimum   fois saison magique pri...   \n",
       "\n",
       "                                            tokenize_text  \n",
       "0             [91, 546, 465, 7, 1754, 407, 8, 5113, 1755]  \n",
       "2                                               [311, 65]  \n",
       "11      [379, 3044, 1756, 780, 528, 5, 2088, 3725, 118...  \n",
       "12                                                 [5114]  \n",
       "23      [4, 366, 8, 83, 1243, 644, 35, 55, 1895, 101, ...  \n",
       "...                                                   ...  \n",
       "295057                          [10, 175, 31, 10169, 401]  \n",
       "295549  [31, 44, 16, 296, 94, 24, 47, 141, 31, 45, 565...  \n",
       "298475                                 [25, 29, 113, 151]  \n",
       "298832  [178, 7, 186, 7, 76, 8, 2212, 366, 42, 16, 403...  \n",
       "299402  [17, 8, 386, 18, 282, 10, 1180, 4, 1179, 7, 23...  \n",
       "\n",
       "[8474 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On visualise le résultat\n",
    "datafinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5821d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On instancie la méthode  de tokenization dans une variable tokenize\n",
    "tokenize= tf.keras.preprocessing.text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d43d0777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puis on applique la tokenization sur le text clean des avis\n",
    "tokenize.fit_on_texts(datafinal[\"review_format_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49347c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d': 1,\n",
       " 'c': 2,\n",
       " 'attraction': 3,\n",
       " 'l': 4,\n",
       " 'parc': 5,\n",
       " 'faire': 6,\n",
       " 'j': 7,\n",
       " 'disney': 8,\n",
       " 'attente': 9,\n",
       " 'magique': 10,\n",
       " 'journée': 11,\n",
       " 'n': 12,\n",
       " 'heure': 13,\n",
       " 'bien': 14,\n",
       " 'trop': 15,\n",
       " 'enfant': 16,\n",
       " 'aller': 17,\n",
       " 'fois': 18,\n",
       " 'pouvoir': 19,\n",
       " 'passer': 20,\n",
       " 'super': 21,\n",
       " 'an': 22,\n",
       " 'petit': 23,\n",
       " 'voir': 24,\n",
       " 'magnifique': 25,\n",
       " 'fermer': 26,\n",
       " 'prix': 27,\n",
       " 'magie': 28,\n",
       " 'monde': 29,\n",
       " 'jour': 30,\n",
       " 'séjour': 31,\n",
       " 'bon': 32,\n",
       " 'beaucoup': 33,\n",
       " 'spectacle': 34,\n",
       " 'qu': 35,\n",
       " 'personnel': 36,\n",
       " 'temps': 37,\n",
       " 'vraiment': 38,\n",
       " 'disneyland': 39,\n",
       " 'parade': 40,\n",
       " 'dommage': 41,\n",
       " 'grand': 42,\n",
       " 'plein': 43,\n",
       " 'top': 44,\n",
       " 'venir': 45,\n",
       " 'hôtel': 46,\n",
       " 'personnage': 47,\n",
       " 'oeil': 48,\n",
       " 'fille': 49,\n",
       " 'cher': 50,\n",
       " 'rien': 51,\n",
       " 's': 52,\n",
       " 'moment': 53,\n",
       " 'revenir': 54,\n",
       " 'falloir': 55,\n",
       " 'déçu': 56,\n",
       " 'pann': 57,\n",
       " 'famille': 58,\n",
       " 'file': 59,\n",
       " 'attendre': 60,\n",
       " 'minute': 61,\n",
       " 'prendre': 62,\n",
       " 'payer': 63,\n",
       " 'queue': 64,\n",
       " 'féerique': 65,\n",
       " 'mickey': 66,\n",
       " 'beau': 67,\n",
       " 'noël': 68,\n",
       " 'retourner': 69,\n",
       " 'endroit': 70,\n",
       " 'superbe': 71,\n",
       " 'm': 72,\n",
       " 'pari': 73,\n",
       " 'manège': 74,\n",
       " 'rêve': 75,\n",
       " 'adore': 76,\n",
       " 'étoile': 77,\n",
       " 'année': 78,\n",
       " 'parking': 79,\n",
       " 'pass': 80,\n",
       " 'min': 81,\n",
       " 'long': 82,\n",
       " 'merveilleux': 83,\n",
       " 'week': 84,\n",
       " 'end': 85,\n",
       " 'adorer': 86,\n",
       " 'hier': 87,\n",
       " 'bémol': 88,\n",
       " 'devoir': 89,\n",
       " 'bel': 90,\n",
       " 'génial': 91,\n",
       " 'fils': 92,\n",
       " 'agréable': 93,\n",
       " 'vouloir': 94,\n",
       " 'chose': 95,\n",
       " 'mettre': 96,\n",
       " 'trouve': 97,\n",
       " 'savoir': 98,\n",
       " 'visite': 99,\n",
       " 'photo': 100,\n",
       " 'autant': 101,\n",
       " 'part': 102,\n",
       " 'restaurant': 103,\n",
       " 'contre': 104,\n",
       " 'jamais': 105,\n",
       " 'problème': 106,\n",
       " 'souvenir': 107,\n",
       " 'rénovation': 108,\n",
       " 'décevoir': 109,\n",
       " 'enfance': 110,\n",
       " 'ratatouille': 111,\n",
       " 'point': 112,\n",
       " 'parfaire': 113,\n",
       " 'aucun': 114,\n",
       " 'tour': 115,\n",
       " 'entrée': 116,\n",
       " 'plaisir': 117,\n",
       " 'tre': 118,\n",
       " 'mal': 119,\n",
       " 'technique': 120,\n",
       " 'propre': 121,\n",
       " 'train': 122,\n",
       " 'billet': 123,\n",
       " 'bonheur': 124,\n",
       " 'coup': 125,\n",
       " 'place': 126,\n",
       " 'euro': 127,\n",
       " 'star': 128,\n",
       " 'froid': 129,\n",
       " 'bref': 130,\n",
       " 'fast': 131,\n",
       " 'princesse': 132,\n",
       " 'décor': 133,\n",
       " '️': 134,\n",
       " 'non': 135,\n",
       " 'excellent': 136,\n",
       " 'sourire': 137,\n",
       " 'studio': 138,\n",
       " 'profiter': 139,\n",
       " 'nuit': 140,\n",
       " 'prochain': 141,\n",
       " 'travail': 142,\n",
       " 'tarif': 143,\n",
       " 'service': 144,\n",
       " 'vite': 145,\n",
       " 'ca': 146,\n",
       " 'période': 147,\n",
       " 'gros': 148,\n",
       " 'manger': 149,\n",
       " 'soir': 150,\n",
       " 'lt': 151,\n",
       " 'anniversaire': 152,\n",
       " 'dernier': 153,\n",
       " 'neige': 154,\n",
       " 'space': 155,\n",
       " 'oublier': 156,\n",
       " 'accueil': 157,\n",
       " 'mieux': 158,\n",
       " 'mine': 159,\n",
       " 'mois': 160,\n",
       " 'simplement': 161,\n",
       " 'trouver': 162,\n",
       " 'rêver': 163,\n",
       " 'arriver': 164,\n",
       " 'boutique': 165,\n",
       " 'adulte': 166,\n",
       " 'panne': 167,\n",
       " 'habitude': 168,\n",
       " 'vrai': 169,\n",
       " 'cast': 170,\n",
       " 'sympa': 171,\n",
       " 'mountain': 172,\n",
       " 'attractier': 173,\n",
       " 'jeu': 174,\n",
       " 'fin': 175,\n",
       " 'passeport': 176,\n",
       " 'pirate': 177,\n",
       " 'oui': 178,\n",
       " 'niveau': 179,\n",
       " 'inoubliable': 180,\n",
       " 'partir': 181,\n",
       " 'eter': 182,\n",
       " 'halloween': 183,\n",
       " 'heureusement': 184,\n",
       " 'bientôt': 185,\n",
       " 'aimer': 186,\n",
       " 'chambre': 187,\n",
       " 'refaire': 188,\n",
       " 'ambiance': 189,\n",
       " 'franchement': 190,\n",
       " 'rester': 191,\n",
       " 'nourriture': 192,\n",
       " 'artifice': 193,\n",
       " 'lieu': 194,\n",
       " 'fan': 195,\n",
       " 'feu': 196,\n",
       " 'samedi': 197,\n",
       " 'qualité': 198,\n",
       " 'maison': 199,\n",
       " 'annuel': 200,\n",
       " 'entrer': 201,\n",
       " 'ouvrir': 202,\n",
       " 'reine': 203,\n",
       " 'semaine': 204,\n",
       " 'émerveiller': 205,\n",
       " 'permettre': 206,\n",
       " 'restauration': 207,\n",
       " 'interminable': 208,\n",
       " 'meilleur': 209,\n",
       " 'final': 210,\n",
       " 'bravo': 211,\n",
       " 'cause': 212,\n",
       " 'vivre': 213,\n",
       " 'perdre': 214,\n",
       " 'sécurité': 215,\n",
       " 'vivement': 216,\n",
       " 'client': 217,\n",
       " 'ami': 218,\n",
       " 'déception': 219,\n",
       " 'rentrer': 220,\n",
       " 'souci': 221,\n",
       " 'nombre': 222,\n",
       " 'bonjour': 223,\n",
       " 'accueillir': 224,\n",
       " 'e': 225,\n",
       " 'hotel': 226,\n",
       " 'repas': 227,\n",
       " 'comprendre': 228,\n",
       " 'donner': 229,\n",
       " 'mauvais': 230,\n",
       " 'aime': 231,\n",
       " 'caraïbe': 232,\n",
       " 'bcp': 233,\n",
       " 'rendez': 234,\n",
       " 'dream': 235,\n",
       " 'tomber': 236,\n",
       " 'négatif': 237,\n",
       " 'fermé': 238,\n",
       " 'pluie': 239,\n",
       " 'revoir': 240,\n",
       " 'sejour': 241,\n",
       " 'malheureusement': 242,\n",
       " 'partout': 243,\n",
       " 'déjeuner': 244,\n",
       " 'sensation': 245,\n",
       " 'normal': 246,\n",
       " 'vie': 247,\n",
       " 'abuser': 248,\n",
       " 'acheter': 249,\n",
       " 'surprise': 250,\n",
       " 'château': 251,\n",
       " 'employé': 252,\n",
       " 'décoration': 253,\n",
       " 'matin': 254,\n",
       " 'site': 255,\n",
       " 'sympathique': 256,\n",
       " 'presque': 257,\n",
       " 'janvier': 258,\n",
       " 'fort': 259,\n",
       " 'member': 260,\n",
       " 'aimable': 261,\n",
       " 'découvrir': 262,\n",
       " 'offrir': 263,\n",
       " 'valoir': 264,\n",
       " 'féerie': 265,\n",
       " 'retourne': 266,\n",
       " 'ouverture': 267,\n",
       " 'prévoir': 268,\n",
       " 'côté': 269,\n",
       " 'journee': 270,\n",
       " 'élevé': 271,\n",
       " 'visiteur': 272,\n",
       " 'illumination': 273,\n",
       " 'opérer': 274,\n",
       " 'war': 275,\n",
       " 'ravir': 276,\n",
       " 'présent': 277,\n",
       " 'dimanche': 278,\n",
       " 'hâter': 279,\n",
       " 'retrouver': 280,\n",
       " 'anglais': 281,\n",
       " 'saison': 282,\n",
       " 'espérer': 283,\n",
       " 'rencontrer': 284,\n",
       " 'impossible': 285,\n",
       " 'devenir': 286,\n",
       " 'pan': 287,\n",
       " 'connaître': 288,\n",
       " 'organisation': 289,\n",
       " 'penser': 290,\n",
       " 'compte': 291,\n",
       " 'soleil': 292,\n",
       " 'finir': 293,\n",
       " 'pays': 294,\n",
       " 'manque': 295,\n",
       " 'heureux': 296,\n",
       " 'rencontre': 297,\n",
       " 'parent': 298,\n",
       " 'chance': 299,\n",
       " 'soirée': 300,\n",
       " 'honteux': 301,\n",
       " 'noel': 302,\n",
       " 'midi': 303,\n",
       " 'changer': 304,\n",
       " 'refair': 305,\n",
       " 'envie': 306,\n",
       " 'davy': 307,\n",
       " 'fastpas': 308,\n",
       " 'aujourd': 309,\n",
       " 'ferme': 310,\n",
       " 'magic': 311,\n",
       " 'mot': 312,\n",
       " 'avai': 313,\n",
       " 'inadmissible': 314,\n",
       " 'manqu': 315,\n",
       " 'fermée': 316,\n",
       " 'peter': 317,\n",
       " 'équipe': 318,\n",
       " 'arrive': 319,\n",
       " 'resto': 320,\n",
       " 'fermeture': 321,\n",
       " 'sûr': 322,\n",
       " 'compter': 323,\n",
       " 'préférer': 324,\n",
       " 'bout': 325,\n",
       " 'expérience': 326,\n",
       " 'content': 327,\n",
       " 'cool': 328,\n",
       " 'moyen': 329,\n",
       " 'demi': 330,\n",
       " 'dreams': 331,\n",
       " 'new': 332,\n",
       " 'santa': 333,\n",
       " 'sortir': 334,\n",
       " 'cas': 335,\n",
       " 'jone': 336,\n",
       " 'boisson': 337,\n",
       " 'accès': 338,\n",
       " 'propreté': 339,\n",
       " 'réserver': 340,\n",
       " 'décembre': 341,\n",
       " 'dur': 342,\n",
       " 'toilette': 343,\n",
       " 'énormément': 344,\n",
       " 'indiana': 345,\n",
       " 'commencer': 346,\n",
       " 'pire': 347,\n",
       " 'positif': 348,\n",
       " 't': 349,\n",
       " 'croire': 350,\n",
       " 'café': 351,\n",
       " 'demander': 352,\n",
       " 'mn': 353,\n",
       " 'âge': 354,\n",
       " 'land': 355,\n",
       " 'ailleurs': 356,\n",
       " 'français': 357,\n",
       " 'redire': 358,\n",
       " 'repartir': 359,\n",
       " 'grâce': 360,\n",
       " 'peine': 361,\n",
       " 'coaster': 362,\n",
       " 'carte': 363,\n",
       " 'nemo': 364,\n",
       " '✨': 365,\n",
       " 'univers': 366,\n",
       " 'organiser': 367,\n",
       " 'pourtant': 368,\n",
       " 'mari': 369,\n",
       " 'partie': 370,\n",
       " 'impression': 371,\n",
       " 'rapport': 372,\n",
       " 'enfer': 373,\n",
       " 'vendredi': 374,\n",
       " 'loin': 375,\n",
       " 'tombe': 376,\n",
       " 'suite': 377,\n",
       " 'mai': 378,\n",
       " 'vacance': 379,\n",
       " 'musique': 380,\n",
       " 'eau': 381,\n",
       " 'passage': 382,\n",
       " 'annoncer': 383,\n",
       " 'animation': 384,\n",
       " 'moitié': 385,\n",
       " 'minimum': 386,\n",
       " 'femme': 387,\n",
       " 'moyenne': 388,\n",
       " 'porte': 389,\n",
       " 'budget': 390,\n",
       " 'france': 391,\n",
       " 'début': 392,\n",
       " 'village': 393,\n",
       " 'buzz': 394,\n",
       " 'fête': 395,\n",
       " 'joie': 396,\n",
       " 'poussette': 397,\n",
       " 'fantastique': 398,\n",
       " 'avis': 399,\n",
       " 'disponible': 400,\n",
       " 'lol': 401,\n",
       " 'joli': 402,\n",
       " 'er': 403,\n",
       " 'tête': 404,\n",
       " 'amuser': 405,\n",
       " 'limite': 406,\n",
       " 'walt': 407,\n",
       " 'indiquer': 408,\n",
       " 'spécial': 409,\n",
       " 'apre': 410,\n",
       " 'fou': 411,\n",
       " 'ranch': 412,\n",
       " 'exorbiter': 413,\n",
       " 'sortie': 414,\n",
       " 'pied': 415,\n",
       " 'féériqu': 416,\n",
       " 'droit': 417,\n",
       " 'énorme': 418,\n",
       " 'pur': 419,\n",
       " 'ensuite': 420,\n",
       " 'demande': 421,\n",
       " 'voiture': 422,\n",
       " 'promener': 423,\n",
       " 'application': 424,\n",
       " 'réservation': 425,\n",
       " 'attent': 426,\n",
       " 'extraordinaire': 427,\n",
       " 'weekend': 428,\n",
       " 'concerner': 429,\n",
       " 'caisse': 430,\n",
       " 'ticket': 431,\n",
       " 'ème': 432,\n",
       " 'novembre': 433,\n",
       " 'fe': 434,\n",
       " 'donne': 435,\n",
       " 'absolument': 436,\n",
       " 'members': 437,\n",
       " 'argent': 438,\n",
       " 'magicien': 439,\n",
       " 'exemple': 440,\n",
       " 'éviter': 441,\n",
       " 'gentil': 442,\n",
       " 'apprécier': 443,\n",
       " 'york': 444,\n",
       " 'montain': 445,\n",
       " 'août': 446,\n",
       " 'plupart': 447,\n",
       " 'correct': 448,\n",
       " 'réalité': 449,\n",
       " 'exorbitant': 450,\n",
       " 'maximum': 451,\n",
       " 'poupée': 452,\n",
       " 'regarder': 453,\n",
       " 'ete': 454,\n",
       " 'pleine': 455,\n",
       " 'fric': 456,\n",
       " 'retomber': 457,\n",
       " 'voyage': 458,\n",
       " 'obliger': 459,\n",
       " 'lodg': 460,\n",
       " 'remplir': 461,\n",
       " 'jeune': 462,\n",
       " 'maintenance': 463,\n",
       " 'fil': 464,\n",
       " 'exceptionnel': 465,\n",
       " 'newport': 466,\n",
       " 'noir': 467,\n",
       " 'sentir': 468,\n",
       " 'crush': 469,\n",
       " 'sublime': 470,\n",
       " 'lundi': 471,\n",
       " 'main': 472,\n",
       " 'park': 473,\n",
       " 'ds': 474,\n",
       " 'cadeau': 475,\n",
       " 'pr': 476,\n",
       " 'cest': 477,\n",
       " 'grandiose': 478,\n",
       " 'manquer': 479,\n",
       " 'nocturne': 480,\n",
       " 'finalement': 481,\n",
       " 'somme': 482,\n",
       " 'amie': 483,\n",
       " 'retournerai': 484,\n",
       " 'ratatouill': 485,\n",
       " 'beal': 486,\n",
       " 'vue': 487,\n",
       " 'arrêter': 488,\n",
       " 'restaurer': 489,\n",
       " 'honte': 490,\n",
       " 'gâcher': 491,\n",
       " 'lumière': 492,\n",
       " 'bay': 493,\n",
       " 'tt': 494,\n",
       " 'sac': 495,\n",
       " 'amoureux': 496,\n",
       " 'gentillesse': 497,\n",
       " 'recommande': 498,\n",
       " 'commercial': 499,\n",
       " 'simple': 500,\n",
       " 'minnie': 501,\n",
       " 'garder': 502,\n",
       " 'pareil': 503,\n",
       " 'formidable': 504,\n",
       " 'principal': 505,\n",
       " 'club': 506,\n",
       " 'juillet': 507,\n",
       " 'hanter': 508,\n",
       " 'septembre': 509,\n",
       " 'conseil': 510,\n",
       " 'chanson': 511,\n",
       " 'menu': 512,\n",
       " 'crockett': 513,\n",
       " 'goût': 514,\n",
       " 'prêt': 515,\n",
       " 'total': 516,\n",
       " 'hic': 517,\n",
       " 'souvenirs': 518,\n",
       " 'attention': 519,\n",
       " 'amp': 520,\n",
       " 'splendide': 521,\n",
       " 'désagréable': 522,\n",
       " 'continuer': 523,\n",
       " 'excessif': 524,\n",
       " 'servir': 525,\n",
       " 'magnifiquer': 526,\n",
       " 'lasse': 527,\n",
       " 'visiter': 528,\n",
       " 'moindre': 529,\n",
       " 'entendre': 530,\n",
       " 'commentaire': 531,\n",
       " 'paradis': 532,\n",
       " 'triste': 533,\n",
       " 'séjourner': 534,\n",
       " 'souhaiter': 535,\n",
       " 'rapide': 536,\n",
       " 'revanche': 537,\n",
       " 'entretenir': 538,\n",
       " 'fonctionner': 539,\n",
       " 'garçon': 540,\n",
       " 'vip': 541,\n",
       " 'cheyenne': 542,\n",
       " 'piscine': 543,\n",
       " 'incroyable': 544,\n",
       " 'reve': 545,\n",
       " 'fabuleux': 546,\n",
       " 'raisonnable': 547,\n",
       " 'zone': 548,\n",
       " 'réaliser': 549,\n",
       " 'suffire': 550,\n",
       " 'question': 551,\n",
       " 'partager': 552,\n",
       " 'proposer': 553,\n",
       " 'parfait': 554,\n",
       " 'anner': 555,\n",
       " 'information': 556,\n",
       " 'ère': 557,\n",
       " 'vendre': 558,\n",
       " 'affluence': 559,\n",
       " 'fumeur': 560,\n",
       " 'renouveler': 561,\n",
       " 'choix': 562,\n",
       " 'séquoia': 563,\n",
       " 'accessible': 564,\n",
       " 'lasser': 565,\n",
       " 'ensemble': 566,\n",
       " 'big': 567,\n",
       " 'ok': 568,\n",
       " 'monsieur': 569,\n",
       " 'bof': 570,\n",
       " 'court': 571,\n",
       " 'complet': 572,\n",
       " 'show': 573,\n",
       " 'retrouve': 574,\n",
       " 'marche': 575,\n",
       " 'magasin': 576,\n",
       " 'tôt': 577,\n",
       " 'jai': 578,\n",
       " 'octobre': 579,\n",
       " 'geste': 580,\n",
       " 'régulièrement': 581,\n",
       " 'ange': 582,\n",
       " 'laisse': 583,\n",
       " 'briller': 584,\n",
       " 'mention': 585,\n",
       " 'hyper': 586,\n",
       " 'réussi': 587,\n",
       " 'food': 588,\n",
       " 'foule': 589,\n",
       " 'retombe': 590,\n",
       " 'thunder': 591,\n",
       " 'prévenir': 592,\n",
       " 'adorable': 593,\n",
       " 'choisir': 594,\n",
       " 'plaindre': 595,\n",
       " 'dormir': 596,\n",
       " 'fonctionne': 597,\n",
       " 'max': 598,\n",
       " 'genial': 599,\n",
       " 'émotion': 600,\n",
       " 'extrêmement': 601,\n",
       " 'impeccable': 602,\n",
       " 'scolaire': 603,\n",
       " 'chaud': 604,\n",
       " 'gratuit': 605,\n",
       " 'jeudi': 606,\n",
       " 'rock': 607,\n",
       " 'mars': 608,\n",
       " 'patience': 609,\n",
       " 'avance': 610,\n",
       " 'chéri': 611,\n",
       " 'attendai': 612,\n",
       " 'manege': 613,\n",
       " 'hât': 614,\n",
       " 'serviable': 615,\n",
       " 'pratique': 616,\n",
       " 'air': 617,\n",
       " 'croiser': 618,\n",
       " 'renseigner': 619,\n",
       " 'remettre': 620,\n",
       " 'hauteur': 621,\n",
       " 'coûte': 622,\n",
       " 'tard': 623,\n",
       " 'enchanter': 624,\n",
       " 'besoin': 625,\n",
       " 'sale': 626,\n",
       " 'éclair': 627,\n",
       " 'sequoia': 628,\n",
       " 'thème': 629,\n",
       " 'roller': 630,\n",
       " 'quasiment': 631,\n",
       " 'avril': 632,\n",
       " 'extrer': 633,\n",
       " 'truc': 634,\n",
       " 'sandwich': 635,\n",
       " 'eme': 636,\n",
       " 'effort': 637,\n",
       " 'totalement': 638,\n",
       " 'général': 639,\n",
       " 'ici': 640,\n",
       " 'remercier': 641,\n",
       " 'redevenir': 642,\n",
       " 'ben': 643,\n",
       " 'regrette': 644,\n",
       " 'etoile': 645,\n",
       " 'manoir': 646,\n",
       " 'appeler': 647,\n",
       " 'prestation': 648,\n",
       " 'complètement': 649,\n",
       " 'coin': 650,\n",
       " 'vol': 651,\n",
       " 'trer': 652,\n",
       " 'terreur': 653,\n",
       " 'date': 654,\n",
       " 'améliorer': 655,\n",
       " 'buffet': 656,\n",
       " 'temp': 657,\n",
       " 'réel': 658,\n",
       " 'loulou': 659,\n",
       " 'port': 660,\n",
       " 'journer': 661,\n",
       " 'cheyenn': 662,\n",
       " 'ensembl': 663,\n",
       " 'peur': 664,\n",
       " 'important': 665,\n",
       " 'internet': 666,\n",
       " 'chaleureux': 667,\n",
       " 'achat': 668,\n",
       " 'patienter': 669,\n",
       " 'répondre': 670,\n",
       " 'direction': 671,\n",
       " 'dis': 672,\n",
       " 'essayer': 673,\n",
       " 'monter': 674,\n",
       " 'crocket': 675,\n",
       " 'terrible': 676,\n",
       " 'concerne': 677,\n",
       " 'mercredi': 678,\n",
       " 'déco': 679,\n",
       " 'espère': 680,\n",
       " 'couper': 681,\n",
       " 'navette': 682,\n",
       " 'mardi': 683,\n",
       " 'difficile': 684,\n",
       " 'cendrillon': 685,\n",
       " 'bouffe': 686,\n",
       " 'réduction': 687,\n",
       " 'interdire': 688,\n",
       " 'chaleur': 689,\n",
       " 'conseille': 690,\n",
       " 'lire': 691,\n",
       " 'dejer': 692,\n",
       " 'tjrs': 693,\n",
       " 'fai': 694,\n",
       " 'marcher': 695,\n",
       " 'problèm': 696,\n",
       " 'staff': 697,\n",
       " 'expliquer': 698,\n",
       " 'instant': 699,\n",
       " 'détail': 700,\n",
       " 'respect': 701,\n",
       " 'gérer': 702,\n",
       " 'coeur': 703,\n",
       " 'decu': 704,\n",
       " 'juin': 705,\n",
       " 'force': 706,\n",
       " 'parcs': 707,\n",
       " 'téléphone': 708,\n",
       " 'avantage': 709,\n",
       " 'faite': 710,\n",
       " 'travailler': 711,\n",
       " 'jolie': 712,\n",
       " 'aim': 713,\n",
       " 'idem': 714,\n",
       " 'enlever': 715,\n",
       " 'décors': 716,\n",
       " 'handicapé': 717,\n",
       " 'rénover': 718,\n",
       " 'résultat': 719,\n",
       " 'bouteille': 720,\n",
       " 'fêter': 721,\n",
       " 'février': 722,\n",
       " 'feeriqu': 723,\n",
       " 'note': 724,\n",
       " 'deco': 725,\n",
       " 'assurer': 726,\n",
       " 'mise': 727,\n",
       " 'bébé': 728,\n",
       " 'pleuvoir': 729,\n",
       " 'machine': 730,\n",
       " 'certe': 731,\n",
       " 'route': 732,\n",
       " 'nouveauté': 733,\n",
       " 'utiliser': 734,\n",
       " 'vif': 735,\n",
       " 'accéder': 736,\n",
       " 'regret': 737,\n",
       " 'çer': 738,\n",
       " 'augmenter': 739,\n",
       " 'jouer': 740,\n",
       " 'hâte': 741,\n",
       " 'arrivée': 742,\n",
       " 'attend': 743,\n",
       " 'wars': 744,\n",
       " 'garde': 745,\n",
       " 'enceint': 746,\n",
       " 'personn': 747,\n",
       " 'second': 748,\n",
       " 'merveille': 749,\n",
       " 'intérieur': 750,\n",
       " 'grave': 751,\n",
       " 'pinocchio': 752,\n",
       " 'système': 753,\n",
       " 'soin': 754,\n",
       " 'merde': 755,\n",
       " 'rentre': 756,\n",
       " 'puce': 757,\n",
       " 'copain': 758,\n",
       " 'changement': 759,\n",
       " 'faute': 760,\n",
       " 'plan': 761,\n",
       " 'asseoir': 762,\n",
       " 'maman': 763,\n",
       " 'we': 764,\n",
       " 'compagnie': 765,\n",
       " 'évidemment': 766,\n",
       " 'wc': 767,\n",
       " 'hamburger': 768,\n",
       " 'solution': 769,\n",
       " 'pavillon': 770,\n",
       " 'joyeux': 771,\n",
       " 'char': 772,\n",
       " 'scandaleux': 773,\n",
       " 'rue': 774,\n",
       " 'âm': 775,\n",
       " 'face': 776,\n",
       " 'salle': 777,\n",
       " 'occasion': 778,\n",
       " 'phare': 779,\n",
       " 'décider': 780,\n",
       " 'scène': 781,\n",
       " 'tjs': 782,\n",
       " 'bateau': 783,\n",
       " 'humeur': 784,\n",
       " 'décevant': 785,\n",
       " 'souriant': 786,\n",
       " 'augmentation': 787,\n",
       " 'extérieur': 788,\n",
       " 'world': 789,\n",
       " 'nickel': 790,\n",
       " 'réponse': 791,\n",
       " 'cours': 792,\n",
       " 'raison': 793,\n",
       " 'vous': 794,\n",
       " 'souffle': 795,\n",
       " 'chercher': 796,\n",
       " 'kilomètre': 797,\n",
       " 'moin': 798,\n",
       " 'méchant': 799,\n",
       " 'incident': 800,\n",
       " 'annuler': 801,\n",
       " 'beauté': 802,\n",
       " 'tapis': 803,\n",
       " 'fée': 804,\n",
       " 'régaler': 805,\n",
       " 'gosse': 806,\n",
       " 'emmener': 807,\n",
       " 'aventure': 808,\n",
       " 'recevoir': 809,\n",
       " 'handicap': 810,\n",
       " 'unique': 811,\n",
       " 'past': 812,\n",
       " 'p': 813,\n",
       " 'vraie': 814,\n",
       " 'refuser': 815,\n",
       " 'lit': 816,\n",
       " 'film': 817,\n",
       " 'uniquement': 818,\n",
       " 'soeur': 819,\n",
       " 'existe': 820,\n",
       " 'haut': 821,\n",
       " 'adapter': 822,\n",
       " 'renovation': 823,\n",
       " 'reviendrai': 824,\n",
       " 'horaire': 825,\n",
       " 'panneau': 826,\n",
       " 'image': 827,\n",
       " 'apporter': 828,\n",
       " 'glace': 829,\n",
       " 'handicaper': 830,\n",
       " 'lendemain': 831,\n",
       " 'burger': 832,\n",
       " 'article': 833,\n",
       " 'loger': 834,\n",
       " 'fé': 835,\n",
       " 'réduire': 836,\n",
       " 'offre': 837,\n",
       " 'astérix': 838,\n",
       " 'street': 839,\n",
       " 'état': 840,\n",
       " 'arrêt': 841,\n",
       " 'horrible': 842,\n",
       " 'quotidien': 843,\n",
       " 'perso': 844,\n",
       " 'terre': 845,\n",
       " 'guest': 846,\n",
       " 'courant': 847,\n",
       " 'dingo': 848,\n",
       " 'choquer': 849,\n",
       " 'dîner': 850,\n",
       " 'aimerais': 851,\n",
       " 'bungalow': 852,\n",
       " 'feux': 853,\n",
       " 'durée': 854,\n",
       " 'chouette': 855,\n",
       " 'informer': 856,\n",
       " 'table': 857,\n",
       " 'installer': 858,\n",
       " 'aerosmith': 859,\n",
       " 'membre': 860,\n",
       " 'voler': 861,\n",
       " 'satisfaire': 862,\n",
       " 'décorer': 863,\n",
       " 'poser': 864,\n",
       " 'lamentable': 865,\n",
       " 'dépenser': 866,\n",
       " 'hont': 867,\n",
       " 'public': 868,\n",
       " 'tower': 869,\n",
       " 'hollywood': 870,\n",
       " 'bientot': 871,\n",
       " 'veux': 872,\n",
       " 'cadre': 873,\n",
       " 'hot': 874,\n",
       " 'dog': 875,\n",
       " 'émerveillement': 876,\n",
       " 'entree': 877,\n",
       " 'milieu': 878,\n",
       " 'facile': 879,\n",
       " 'respecter': 880,\n",
       " 'gueule': 881,\n",
       " 'réellement': 882,\n",
       " 'baisser': 883,\n",
       " 'chateau': 884,\n",
       " 'esprit': 885,\n",
       " 'dame': 886,\n",
       " 'couple': 887,\n",
       " 'baisse': 888,\n",
       " 'taire': 889,\n",
       " 'peluche': 890,\n",
       " 'préparer': 891,\n",
       " 'genre': 892,\n",
       " 'larme': 893,\n",
       " 'compensation': 894,\n",
       " 'lever': 895,\n",
       " 'malgrer': 896,\n",
       " 'clairement': 897,\n",
       " 'gagner': 898,\n",
       " 'annee': 899,\n",
       " 'impatience': 900,\n",
       " 'bras': 901,\n",
       " 'accompagner': 902,\n",
       " 'rapidement': 903,\n",
       " 'europapark': 904,\n",
       " 'agent': 905,\n",
       " 'papa': 906,\n",
       " 'exagérer': 907,\n",
       " 'journé': 908,\n",
       " 'météo': 909,\n",
       " 'quell': 910,\n",
       " 'dégoûter': 911,\n",
       " 'accord': 912,\n",
       " 'constater': 913,\n",
       " 'envoyer': 914,\n",
       " 'pizza': 915,\n",
       " 'terminer': 916,\n",
       " 'mitiger': 917,\n",
       " 'surprendre': 918,\n",
       " 'pub': 919,\n",
       " 'pension': 920,\n",
       " 'millimètre': 921,\n",
       " 'costume': 922,\n",
       " 'profite': 923,\n",
       " 'réparation': 924,\n",
       " 'x': 925,\n",
       " 'pot': 926,\n",
       " 'bonsoir': 927,\n",
       " 'gamin': 928,\n",
       " 'compliquer': 929,\n",
       " 'quasi': 930,\n",
       " 'demie': 931,\n",
       " 'hyperspace': 932,\n",
       " 'intérêt': 933,\n",
       " 'immense': 934,\n",
       " 'différence': 935,\n",
       " 'ect': 936,\n",
       " 'small': 937,\n",
       " 'situation': 938,\n",
       " 'message': 939,\n",
       " 'mail': 940,\n",
       " 'événement': 941,\n",
       " 'hanté': 942,\n",
       " 'lieux': 943,\n",
       " 'dispo': 944,\n",
       " 'amabilité': 945,\n",
       " 'père': 946,\n",
       " 'em': 947,\n",
       " 'vendeur': 948,\n",
       " 'succès': 949,\n",
       " 'idée': 950,\n",
       " 'écoute': 951,\n",
       " 'grosse': 952,\n",
       " 'éveillé': 953,\n",
       " 'mini': 954,\n",
       " 'dizaine': 955,\n",
       " 'balader': 956,\n",
       " 'régler': 957,\n",
       " 'pleurer': 958,\n",
       " 'habituer': 959,\n",
       " 'évacuer': 960,\n",
       " 'effectivement': 961,\n",
       " 'arnaqu': 962,\n",
       " 'allée': 963,\n",
       " 'condition': 964,\n",
       " 'aider': 965,\n",
       " 'forcément': 966,\n",
       " 'lorsqu': 967,\n",
       " 'conte': 968,\n",
       " 'facilement': 969,\n",
       " 'reprise': 970,\n",
       " 'faux': 971,\n",
       " 'autour': 972,\n",
       " 'perte': 973,\n",
       " 'rire': 974,\n",
       " 'aurai': 975,\n",
       " 'explication': 976,\n",
       " 'produit': 977,\n",
       " 'employer': 978,\n",
       " 'courir': 979,\n",
       " 'in': 980,\n",
       " 'quelqu': 981,\n",
       " 'agreabl': 982,\n",
       " 'découverte': 983,\n",
       " 'atraction': 984,\n",
       " 'guichet': 985,\n",
       " 'certainement': 986,\n",
       " 'irréprochable': 987,\n",
       " 'tellemer': 988,\n",
       " 'éclater': 989,\n",
       " 'frite': 990,\n",
       " 'arrête': 991,\n",
       " 'souhaite': 992,\n",
       " 'priorité': 993,\n",
       " 'détour': 994,\n",
       " 'bloquer': 995,\n",
       " 'fond': 996,\n",
       " 'médiocre': 997,\n",
       " 'particulièrement': 998,\n",
       " 'amélioration': 999,\n",
       " 're': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#~Regardons de quoi à l'air la liste de token et le numéro associé à chaque mot\n",
    "tokenize.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c74350c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-8ba99660fb83>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datafinal[\"tokenize_text\"]= tokenize.texts_to_sequences(datafinal[\"review_format_clean\"])\n"
     ]
    }
   ],
   "source": [
    "# On enregistre les phrases tokenizer dans une nouvelle colonne de notre dataframe\n",
    "# Avec la méthode texts_to_sequences\n",
    "datafinal[\"tokenize_text\"]= tokenize.texts_to_sequences(datafinal[\"review_format_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3d2507c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_format</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_format_clean</th>\n",
       "      <th>tokenize_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>génial  fabuleux  exceptionnel   j aimerais qu...</td>\n",
       "      <td>5</td>\n",
       "      <td>génial   fabuleux   exceptionnel    j aimerai ...</td>\n",
       "      <td>[91, 546, 465, 7, 1754, 407, 8, 5113, 1755]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toujours aussi magic  féerique</td>\n",
       "      <td>5</td>\n",
       "      <td>magic   féerique</td>\n",
       "      <td>[311, 65]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>en vacances en région parisienne nous nous som...</td>\n",
       "      <td>2</td>\n",
       "      <td>vacance région parisien décider visiter parc r...</td>\n",
       "      <td>[379, 3044, 1756, 780, 528, 5, 2088, 3725, 118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tropbeaufinalpleinlesyeuxoreil</td>\n",
       "      <td>5</td>\n",
       "      <td>tropbeaufinalpleinlesyeuxoreil</td>\n",
       "      <td>[5114]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>l univers disney reste merveilleux  toutefois ...</td>\n",
       "      <td>4</td>\n",
       "      <td>l univers disney merveilleux   toutefois regre...</td>\n",
       "      <td>[4, 366, 8, 83, 1243, 644, 35, 55, 1895, 101, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295057</th>\n",
       "      <td>toujours aussi magique même si à la fin du séj...</td>\n",
       "      <td>5</td>\n",
       "      <td>magique fin séjour rotule lol</td>\n",
       "      <td>[10, 175, 31, 10169, 401]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295549</th>\n",
       "      <td>séjour au top    mes enfants les plus heureux ...</td>\n",
       "      <td>5</td>\n",
       "      <td>séjour top     enfant heureux vouloir voir per...</td>\n",
       "      <td>[31, 44, 16, 296, 94, 24, 47, 141, 31, 45, 565...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298475</th>\n",
       "      <td>magnifique un monde parfait  lt</td>\n",
       "      <td>5</td>\n",
       "      <td>magnifique monde parfaire   lt</td>\n",
       "      <td>[25, 29, 113, 151]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298832</th>\n",
       "      <td>oui j ai aimé car j adore disney et tout ce qu...</td>\n",
       "      <td>4</td>\n",
       "      <td>oui j aimer j adore disney touche univers     ...</td>\n",
       "      <td>[178, 7, 186, 7, 76, 8, 2212, 366, 42, 16, 403...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299402</th>\n",
       "      <td>je vais à disney minimum  fois par saison car ...</td>\n",
       "      <td>5</td>\n",
       "      <td>aller disney minimum   fois saison magique pri...</td>\n",
       "      <td>[17, 8, 386, 18, 282, 10, 1180, 4, 1179, 7, 23...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8474 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_format  stars  \\\n",
       "0       génial  fabuleux  exceptionnel   j aimerais qu...      5   \n",
       "2                        toujours aussi magic  féerique        5   \n",
       "11      en vacances en région parisienne nous nous som...      2   \n",
       "12                         tropbeaufinalpleinlesyeuxoreil      5   \n",
       "23      l univers disney reste merveilleux  toutefois ...      4   \n",
       "...                                                   ...    ...   \n",
       "295057  toujours aussi magique même si à la fin du séj...      5   \n",
       "295549  séjour au top    mes enfants les plus heureux ...      5   \n",
       "298475                   magnifique un monde parfait  lt       5   \n",
       "298832  oui j ai aimé car j adore disney et tout ce qu...      4   \n",
       "299402  je vais à disney minimum  fois par saison car ...      5   \n",
       "\n",
       "                                      review_format_clean  \\\n",
       "0       génial   fabuleux   exceptionnel    j aimerai ...   \n",
       "2                                      magic   féerique     \n",
       "11      vacance région parisien décider visiter parc r...   \n",
       "12                         tropbeaufinalpleinlesyeuxoreil   \n",
       "23      l univers disney merveilleux   toutefois regre...   \n",
       "...                                                   ...   \n",
       "295057                      magique fin séjour rotule lol   \n",
       "295549  séjour top     enfant heureux vouloir voir per...   \n",
       "298475                     magnifique monde parfaire   lt   \n",
       "298832  oui j aimer j adore disney touche univers     ...   \n",
       "299402  aller disney minimum   fois saison magique pri...   \n",
       "\n",
       "                                            tokenize_text  \n",
       "0             [91, 546, 465, 7, 1754, 407, 8, 5113, 1755]  \n",
       "2                                               [311, 65]  \n",
       "11      [379, 3044, 1756, 780, 528, 5, 2088, 3725, 118...  \n",
       "12                                                 [5114]  \n",
       "23      [4, 366, 8, 83, 1243, 644, 35, 55, 1895, 101, ...  \n",
       "...                                                   ...  \n",
       "295057                          [10, 175, 31, 10169, 401]  \n",
       "295549  [31, 44, 16, 296, 94, 24, 47, 141, 31, 45, 565...  \n",
       "298475                                 [25, 29, 113, 151]  \n",
       "298832  [178, 7, 186, 7, 76, 8, 2212, 366, 42, 16, 403...  \n",
       "299402  [17, 8, 386, 18, 282, 10, 1180, 4, 1179, 7, 23...  \n",
       "\n",
       "[8474 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jetons un oeil à notre BDD finale\n",
    "datafinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f8274a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On met tous les lignes à la même taille de token\n",
    "# Avec la méthode pad_sequences\n",
    "# Sinon le modèle ne peut pas s'entraîner\n",
    "# On enregistre la liste de phrases tokenizé et mis à la même longueur dans la variable pad_review\n",
    "pad_review = tf.keras.preprocessing.sequence.pad_sequences(datafinal[\"tokenize_text\"],padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5bdcb132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  91,  546,  465, ...,    0,    0,    0],\n",
       "       [ 311,   65,    0, ...,    0,    0,    0],\n",
       "       [ 379, 3044, 1756, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  25,   29,  113, ...,    0,    0,    0],\n",
       "       [ 178,    7,  186, ...,    0,    0,    0],\n",
       "       [  17,    8,  386, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78dbf2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enregistre les 2 colonnes dont on a besoin dans une nouvelle variable\n",
    "# C'est ce dont on va se servir pour entraîner notre modèle puis le tester\n",
    "encode_data =tf.data.Dataset.from_tensor_slices((pad_review,datafinal[\"stars\"].values-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "effa4209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On choisit la taille de notre échantillon d'entraînement\n",
    "# Ici on prend 80 % de la taille de notre dataset\n",
    "size = int(len(datafinal[\"stars\"])*0.8)\n",
    "all_encoded_data = encode_data.shuffle(len(datafinal[\"stars\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "002369d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enregistre dans la variable train_data l'échantillon d'entraînement\n",
    "train_data = all_encoded_data.take(size)\n",
    "# On groupe les données par 16 afin d'optimiser et de stabiliser l'entraînement du modèle\n",
    "train_data = train_data.batch(16)\n",
    "\n",
    "# On enregistre dans la variable test_data l'échantillon qui nous permet de tester le modèle\n",
    "test_data= all_encoded_data.skip(size)\n",
    "# On groupe également les données par 16 \n",
    "test_data = test_data.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "396ea622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[223  41  97 ...   0   0   0]\n",
      " [ 21 473  17 ...   0   0   0]\n",
      " [ 28  37   1 ...   0   0   0]\n",
      " ...\n",
      " [ 28 214  33 ...   0   0   0]\n",
      " [ 32  11   3 ...   0   0   0]\n",
      " [ 10   0   0 ...   0   0   0]], shape=(16, 248), dtype=int32) tf.Tensor([4 3 4 2 4 4 3 4 4 3 4 4 4 1 3 4], shape=(16,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# On regarde que les deux commandes ont bien marché sur nos échantillons\n",
    "for review,stars in test_data.take(1):\n",
    "    print(review, stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c72fc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10169"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenize.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b1a480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enregistre la taille du vocabulaire de notre dataset dans la variable vocab_size\n",
    "vocab_size = len(tokenize.word_index)\n",
    "\n",
    "# On créé le modèle de réseaux de neurones qui va nous permettre de créer notre modèle prédictif\n",
    "model = tf.keras.Sequential([\n",
    "    # La première couche du réseau est celle qui va recevoir l'ensemble du dictionnaire de mot\n",
    "    # Ici on fixe donc la taille de neurones à la taille du dictionnaire +1 (car le compte commence à 0 en python)\n",
    "    tf.keras.layers.Embedding(vocab_size+1,64,input_shape=[review.shape[1],]),\n",
    "    # On ajoute une couche de neurones de convolutions qui va synthétiser l'information sortant de la première couche\n",
    "    # L'output ne sera que sur 1  seule dimensions\n",
    "    tf.keras.layers.Conv1D(16,3, activation='relu'),\n",
    "    # La couche Flatten va transformer les outputs de la couche précèdente (dimension 16*3)\n",
    "    # En un vecteur d'input pour les prochaines couches (dimension 48*1)\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # On utilise alors des couches de réseaux avec 64 neurones\n",
    "    tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "    # Puis 32\n",
    "    tf.keras.layers.Dense(32,activation=\"relu\"),\n",
    "    # Puis 16\n",
    "    tf.keras.layers.Dense(16,activation=\"relu\"),\n",
    "    # Puis 8\n",
    "    tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "    # Et enfin, la dernière couche comportera autant de neurones (et donc d'output)\n",
    "    # Que notre variable target \n",
    "    # Qui ici possède 5 modalités (de 1 à 5 étoiles par avis)\n",
    "    tf.keras.layers.Dense(5,activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a50929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implémentation du schéma d'apprentissage du modèle\n",
    "\n",
    "## On fixe le taux d'apprentissage à 0.1 % ce qui est la norme\n",
    "learning_rate = 0.001\n",
    "\n",
    "## On enregistre dans la variable lr_schedule\n",
    "## L'ensemble des éléments de notre schéma d'apprentissage\n",
    "lr_schedule= tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                # On met le taux d'apprentissage qu'on a enregistré\n",
    "                learning_rate,\n",
    "                # Nombre d'étape avant la diminution du taux d'apprentissage du modèle\n",
    "                decay_steps= 10000,\n",
    "                # De combien décroit le taux d'apprentissage? ici de 96%\n",
    "                decay_rate= 0.96,\n",
    "                # Cet argument staircase= True veut juste dire qu'on va suivre\n",
    "                # Un schéma de décroissance du taux d'apprentissage en escalier\n",
    "                # Qui dépendra du taux d'apprentissage et du nombre de pas prévu avant la fin \n",
    "                staircase=True                \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a268624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fixe l'optimiseur qu'on choisit pour notre modèle\n",
    "optimizer= tf.keras.optimizers.Adam(\n",
    "    # On fixe le schéma d'apprentissage de notre modèle\n",
    "    \n",
    "    learning_rate=lr_schedule\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cebd1619",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compilation du modèle\n",
    "model.compile(optimizer=optimizer, # On définit un optimiseur\n",
    "             loss= tf.keras.losses.SparseCategoricalCrossentropy(), # On définit la mesure de la fonction de perte\n",
    "             metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]) # On définit la métrique de précision du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d04b4861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "424/424 [==============================] - 5s 10ms/step - loss: 1.0158 - sparse_categorical_accuracy: 0.6138 - val_loss: 0.8250 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 2/40\n",
      "424/424 [==============================] - 4s 10ms/step - loss: 0.8157 - sparse_categorical_accuracy: 0.6690 - val_loss: 0.7038 - val_sparse_categorical_accuracy: 0.7215\n",
      "Epoch 3/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.7150 - sparse_categorical_accuracy: 0.7056 - val_loss: 0.6121 - val_sparse_categorical_accuracy: 0.7475\n",
      "Epoch 4/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.6180 - sparse_categorical_accuracy: 0.7578 - val_loss: 0.5280 - val_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 5/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.5323 - sparse_categorical_accuracy: 0.7933 - val_loss: 0.4312 - val_sparse_categorical_accuracy: 0.8383\n",
      "Epoch 6/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.4380 - sparse_categorical_accuracy: 0.8335 - val_loss: 0.3546 - val_sparse_categorical_accuracy: 0.8684\n",
      "Epoch 7/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.3549 - sparse_categorical_accuracy: 0.8566 - val_loss: 0.2996 - val_sparse_categorical_accuracy: 0.8867\n",
      "Epoch 8/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.3103 - sparse_categorical_accuracy: 0.8813 - val_loss: 0.2325 - val_sparse_categorical_accuracy: 0.9097\n",
      "Epoch 9/40\n",
      "424/424 [==============================] - 4s 10ms/step - loss: 0.2664 - sparse_categorical_accuracy: 0.8932 - val_loss: 0.2077 - val_sparse_categorical_accuracy: 0.9268\n",
      "Epoch 10/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.2302 - sparse_categorical_accuracy: 0.9143 - val_loss: 0.2081 - val_sparse_categorical_accuracy: 0.9233\n",
      "Epoch 11/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.2063 - sparse_categorical_accuracy: 0.9254 - val_loss: 0.1549 - val_sparse_categorical_accuracy: 0.9410\n",
      "Epoch 12/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.1676 - sparse_categorical_accuracy: 0.9426 - val_loss: 0.1304 - val_sparse_categorical_accuracy: 0.9622\n",
      "Epoch 13/40\n",
      "424/424 [==============================] - 4s 10ms/step - loss: 0.1324 - sparse_categorical_accuracy: 0.9571 - val_loss: 0.0917 - val_sparse_categorical_accuracy: 0.9711\n",
      "Epoch 14/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.1207 - sparse_categorical_accuracy: 0.9612 - val_loss: 0.0972 - val_sparse_categorical_accuracy: 0.9740\n",
      "Epoch 15/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0934 - sparse_categorical_accuracy: 0.9706 - val_loss: 0.0786 - val_sparse_categorical_accuracy: 0.9776\n",
      "Epoch 16/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0838 - sparse_categorical_accuracy: 0.9739 - val_loss: 0.0894 - val_sparse_categorical_accuracy: 0.9746\n",
      "Epoch 17/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0827 - sparse_categorical_accuracy: 0.9734 - val_loss: 0.0633 - val_sparse_categorical_accuracy: 0.9858A: 2s - loss\n",
      "Epoch 18/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0802 - sparse_categorical_accuracy: 0.9746 - val_loss: 0.0625 - val_sparse_categorical_accuracy: 0.9817\n",
      "Epoch 19/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0730 - sparse_categorical_accuracy: 0.9782 - val_loss: 0.0540 - val_sparse_categorical_accuracy: 0.9864\n",
      "Epoch 20/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0603 - sparse_categorical_accuracy: 0.9822 - val_loss: 0.0522 - val_sparse_categorical_accuracy: 0.9841\n",
      "Epoch 21/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0590 - sparse_categorical_accuracy: 0.9835 - val_loss: 0.0442 - val_sparse_categorical_accuracy: 0.9853\n",
      "Epoch 22/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0520 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.0414 - val_sparse_categorical_accuracy: 0.9858\n",
      "Epoch 23/40\n",
      "424/424 [==============================] - 4s 10ms/step - loss: 0.0522 - sparse_categorical_accuracy: 0.9823 - val_loss: 0.0390 - val_sparse_categorical_accuracy: 0.9882\n",
      "Epoch 24/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0569 - sparse_categorical_accuracy: 0.9842 - val_loss: 0.0258 - val_sparse_categorical_accuracy: 0.9935\n",
      "Epoch 25/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0378 - sparse_categorical_accuracy: 0.9891 - val_loss: 0.0327 - val_sparse_categorical_accuracy: 0.9917\n",
      "Epoch 26/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0341 - sparse_categorical_accuracy: 0.9894 - val_loss: 0.0294 - val_sparse_categorical_accuracy: 0.9906\n",
      "Epoch 27/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0275 - sparse_categorical_accuracy: 0.9920 - val_loss: 0.0246 - val_sparse_categorical_accuracy: 0.9923\n",
      "Epoch 28/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0376 - sparse_categorical_accuracy: 0.9879 - val_loss: 0.0265 - val_sparse_categorical_accuracy: 0.9917\n",
      "Epoch 29/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0369 - sparse_categorical_accuracy: 0.9873 - val_loss: 0.0470 - val_sparse_categorical_accuracy: 0.9935\n",
      "Epoch 30/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0472 - sparse_categorical_accuracy: 0.9873 - val_loss: 0.0243 - val_sparse_categorical_accuracy: 0.9947\n",
      "Epoch 31/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0315 - sparse_categorical_accuracy: 0.9917 - val_loss: 0.0146 - val_sparse_categorical_accuracy: 0.9941\n",
      "Epoch 32/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0249 - sparse_categorical_accuracy: 0.9923 - val_loss: 0.0121 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 33/40\n",
      "424/424 [==============================] - 4s 10ms/step - loss: 0.0262 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.0153 - val_sparse_categorical_accuracy: 0.9953\n",
      "Epoch 34/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0171 - sparse_categorical_accuracy: 0.9954 - val_loss: 0.0136 - val_sparse_categorical_accuracy: 0.9953\n",
      "Epoch 35/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0172 - sparse_categorical_accuracy: 0.9947 - val_loss: 0.0168 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 36/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0261 - sparse_categorical_accuracy: 0.9916 - val_loss: 0.0390 - val_sparse_categorical_accuracy: 0.9906\n",
      "Epoch 37/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0433 - sparse_categorical_accuracy: 0.9900 - val_loss: 0.0241 - val_sparse_categorical_accuracy: 0.9923\n",
      "Epoch 38/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0247 - sparse_categorical_accuracy: 0.9917 - val_loss: 0.0112 - val_sparse_categorical_accuracy: 0.9976\n",
      "Epoch 39/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0277 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0152 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 40/40\n",
      "424/424 [==============================] - 4s 10ms/step - loss: 0.0148 - sparse_categorical_accuracy: 0.9959 - val_loss: 0.0180 - val_sparse_categorical_accuracy: 0.9947\n"
     ]
    }
   ],
   "source": [
    "## Entraînement du modèle\n",
    "# Sur notre échantillon d'entraînement\n",
    "# Le nombre d'epochs correspond au nombre de fois que le modèle va parcourir notre dataset \n",
    "history = model.fit(train_data,epochs=40,validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b741dc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    4881\n",
       "4    1538\n",
       "3    1010\n",
       "1     558\n",
       "2     487\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On regarde si toutes nos classes sont représentés de manière homogène\n",
    "datafinal[\"stars\"].value_counts()\n",
    "# On voit que ce n'est pas le cas ici\n",
    "# On va donc modifier légèrement notre modèle\n",
    "# Pour qu'on ait des poids quasi-uniformes pour chaque catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "45b23716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On rajoute un paramètre supplémentaire\n",
    "# Les weight vont paramètrer le poids de chaque catégorie de notre variable target\n",
    "# Dans l'apprentissage de notre modèle\n",
    "# Ici, les rang 4 et 5 sont sur-représentés dans notre dataset\n",
    "# Donc en diminue le poids\n",
    "# On fait l'inverse pour les rang 1 et 2 qui sont sous-représentés\n",
    "weight_dic= {\n",
    "    0:0,\n",
    "    1:2,\n",
    "    2:2,\n",
    "    3:1,\n",
    "    4:0.7,\n",
    "    5:0.30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c6276cb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "424/424 [==============================] - 4s 10ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0081 - val_sparse_categorical_accuracy: 0.9959\n",
      "Epoch 2/40\n",
      "424/424 [==============================] - 4s 10ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0078 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 3/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 0.9994\n",
      "Epoch 4/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0028 - val_sparse_categorical_accuracy: 0.9988\n",
      "Epoch 5/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0071 - val_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 6/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0042 - val_sparse_categorical_accuracy: 0.9988\n",
      "Epoch 7/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 0.9994\n",
      "Epoch 8/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0051 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 9/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 10/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0049 - val_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 11/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0244 - sparse_categorical_accuracy: 0.9913 - val_loss: 0.0938 - val_sparse_categorical_accuracy: 0.9864\n",
      "Epoch 12/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9824 - val_loss: 0.0970 - val_sparse_categorical_accuracy: 0.9864\n",
      "Epoch 13/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.0572 - val_sparse_categorical_accuracy: 0.9864\n",
      "Epoch 14/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9863 - val_loss: 0.0559 - val_sparse_categorical_accuracy: 0.9900\n",
      "Epoch 15/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9857 - val_loss: 0.0932 - val_sparse_categorical_accuracy: 0.9823\n",
      "Epoch 16/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9845 - val_loss: 0.0869 - val_sparse_categorical_accuracy: 0.9858\n",
      "Epoch 17/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9824 - val_loss: 0.1375 - val_sparse_categorical_accuracy: 0.9817\n",
      "Epoch 18/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9801 - val_loss: 0.1229 - val_sparse_categorical_accuracy: 0.9870\n",
      "Epoch 19/40\n",
      "424/424 [==============================] - 4s 10ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.0961 - val_sparse_categorical_accuracy: 0.9870\n",
      "Epoch 20/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0936 - val_sparse_categorical_accuracy: 0.9853\n",
      "Epoch 21/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9850 - val_loss: 0.1869 - val_sparse_categorical_accuracy: 0.9740\n",
      "Epoch 22/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.1434 - val_sparse_categorical_accuracy: 0.9823\n",
      "Epoch 23/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9770 - val_loss: 0.2495 - val_sparse_categorical_accuracy: 0.9587\n",
      "Epoch 24/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9563 - val_loss: 0.2363 - val_sparse_categorical_accuracy: 0.9658\n",
      "Epoch 25/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9597 - val_loss: 0.2903 - val_sparse_categorical_accuracy: 0.9587\n",
      "Epoch 26/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9628 - val_loss: 0.2647 - val_sparse_categorical_accuracy: 0.9605\n",
      "Epoch 27/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9594 - val_loss: 0.3018 - val_sparse_categorical_accuracy: 0.9605\n",
      "Epoch 28/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9572 - val_loss: 0.3553 - val_sparse_categorical_accuracy: 0.9605\n",
      "Epoch 29/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0033 - sparse_categorical_accuracy: 0.9581 - val_loss: 0.3190 - val_sparse_categorical_accuracy: 0.9581\n",
      "Epoch 30/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9540 - val_loss: 0.4581 - val_sparse_categorical_accuracy: 0.9575\n",
      "Epoch 31/40\n",
      "424/424 [==============================] - 5s 11ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9555 - val_loss: 0.4328 - val_sparse_categorical_accuracy: 0.9540\n",
      "Epoch 32/40\n",
      "424/424 [==============================] - 4s 10ms/step - loss: 0.0030 - sparse_categorical_accuracy: 0.9555 - val_loss: 0.4270 - val_sparse_categorical_accuracy: 0.9534\n",
      "Epoch 33/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9524 - val_loss: 0.3936 - val_sparse_categorical_accuracy: 0.9552\n",
      "Epoch 34/40\n",
      "424/424 [==============================] - 4s 10ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9565 - val_loss: 0.4685 - val_sparse_categorical_accuracy: 0.9552\n",
      "Epoch 35/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0116 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.6197 - val_sparse_categorical_accuracy: 0.9504\n",
      "Epoch 36/40\n",
      "424/424 [==============================] - 4s 10ms/step - loss: 0.0244 - sparse_categorical_accuracy: 0.9575 - val_loss: 0.4441 - val_sparse_categorical_accuracy: 0.9534\n",
      "Epoch 37/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9562 - val_loss: 0.4826 - val_sparse_categorical_accuracy: 0.9522\n",
      "Epoch 38/40\n",
      "424/424 [==============================] - 4s 10ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9559 - val_loss: 0.5191 - val_sparse_categorical_accuracy: 0.9575\n",
      "Epoch 39/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.9558\n",
      "Epoch 40/40\n",
      "424/424 [==============================] - 4s 9ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9587 - val_loss: 0.7216 - val_sparse_categorical_accuracy: 0.9440\n"
     ]
    }
   ],
   "source": [
    "# On ré-entraîne notre modèle, cette fois ci avec les poids en paramètres\n",
    "history = model.fit(train_data,epochs=40,validation_data=test_data,class_weight=weight_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a0a872f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Catégorie prédite : 3\n",
      "Véritable catégorie : 3\n",
      "Probabilité de la prédiction : 99.99288177490234 %\n",
      "1\n",
      "Catégorie prédite : 3\n",
      "Véritable catégorie : 3\n",
      "Probabilité de la prédiction : 99.99996185302734 %\n",
      "2\n",
      "Catégorie prédite : 3\n",
      "Véritable catégorie : 3\n",
      "Probabilité de la prédiction : 100.0 %\n",
      "3\n",
      "Catégorie prédite : 4\n",
      "Véritable catégorie : 4\n",
      "Probabilité de la prédiction : 99.99993896484375 %\n",
      "4\n",
      "Catégorie prédite : 4\n",
      "Véritable catégorie : 4\n",
      "Probabilité de la prédiction : 99.99603271484375 %\n",
      "5\n",
      "Catégorie prédite : 4\n",
      "Véritable catégorie : 4\n",
      "Probabilité de la prédiction : 100.0 %\n",
      "6\n",
      "Catégorie prédite : 0\n",
      "Véritable catégorie : 0\n",
      "Probabilité de la prédiction : 100.0 %\n",
      "7\n",
      "Catégorie prédite : 3\n",
      "Véritable catégorie : 3\n",
      "Probabilité de la prédiction : 99.9999771118164 %\n",
      "8\n",
      "Catégorie prédite : 2\n",
      "Véritable catégorie : 2\n",
      "Probabilité de la prédiction : 99.81684875488281 %\n",
      "9\n",
      "Catégorie prédite : 4\n",
      "Véritable catégorie : 4\n",
      "Probabilité de la prédiction : 100.0 %\n",
      "10\n",
      "Catégorie prédite : 4\n",
      "Véritable catégorie : 4\n",
      "Probabilité de la prédiction : 100.0 %\n",
      "11\n",
      "Catégorie prédite : 3\n",
      "Véritable catégorie : 3\n",
      "Probabilité de la prédiction : 100.0 %\n",
      "12\n",
      "Catégorie prédite : 2\n",
      "Véritable catégorie : 2\n",
      "Probabilité de la prédiction : 99.99998474121094 %\n",
      "13\n",
      "Catégorie prédite : 3\n",
      "Véritable catégorie : 3\n",
      "Probabilité de la prédiction : 100.0 %\n",
      "14\n",
      "Catégorie prédite : 4\n",
      "Véritable catégorie : 4\n",
      "Probabilité de la prédiction : 100.0 %\n"
     ]
    }
   ],
   "source": [
    "## Essai sur un batch\n",
    "for i in range(15):\n",
    "    for example, sh in test_data.take(1):\n",
    "        print(i)\n",
    "        print(\"Catégorie prédite : {}\".format(np.argmax(model.predict(example)[i])))\n",
    "        print(\"Véritable catégorie : {}\".format(sh[i]))\n",
    "        print(\"Probabilité de la prédiction : {} %\".format(np.max(model.predict(example)[i] * 100).astype(\"float\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "91e5c996",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\nicol\\Desktop\\NLPfinalized_model_Sentiment_analysis\\assets\n"
     ]
    }
   ],
   "source": [
    "filename = 'C:\\Users\\nicol\\Desktop\\NLPfinalized_model_Sentiment_analysis'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62c8f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
